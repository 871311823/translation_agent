import os
import re
import json
import threading
import sys
from glob import glob
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Tuple, Optional
import time

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ process æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

import gradio as gr
from process import (
    diff_texts,
    extract_docx,
    extract_pdf,
    extract_text,
    model_load,
    translator,
    translator_sec,
)

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE = os.path.join(os.path.dirname(__file__), "user_config.json")

# å…¨å±€å˜é‡
translation_tasks = {}  # å­˜å‚¨ç¿»è¯‘ä»»åŠ¡çŠ¶æ€
task_counter = 0
MAX_CONCURRENT_TASKS = 5  # æœ€å¤§å¹¶å‘æ•°

# æ ‡å¿—ï¼šæ˜¯å¦æ­£åœ¨åŠ è½½é…ç½®
is_loading_config = False


class TranslationTask:
    """ç¿»è¯‘ä»»åŠ¡ç±»"""
    def __init__(self, task_id: str, filename: str, content: str):
        self.task_id = task_id
        self.filename = filename
        self.content = content
        self.status = "ç­‰å¾…ä¸­"  # ç­‰å¾…ä¸­, ç¿»è¯‘ä¸­, å·²å®Œæˆ, å¤±è´¥
        self.progress = 0
        self.init_translation = ""
        self.reflect_translation = ""
        self.final_translation = ""
        self.error_message = ""
        self.start_time = None
        self.end_time = None


def save_config(
    endpoint, model, api_key, base,
    endpoint2, model2, api_key2, base2,
    source_lang, target_lang, country,
    max_tokens, temperature, rpm, choice
):
    """ä¿å­˜é…ç½®åˆ°æœ¬åœ°æ–‡ä»¶"""
    try:
        config = {
            "endpoint": endpoint,
            "model": model,
            "api_key": api_key,
            "base": base,
            "endpoint2": endpoint2,
            "model2": model2,
            "api_key2": api_key2,
            "base2": base2,
            "source_lang": source_lang,
            "target_lang": target_lang,
            "country": country,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "rpm": rpm,
            "choice": choice,
        }
        with open(CONFIG_FILE, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return gr.update(value="âœ… é…ç½®å·²ä¿å­˜", visible=True)
    except Exception as e:
        return gr.update(value=f"âŒ ä¿å­˜å¤±è´¥: {e}", visible=True)


def load_config():
    """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½é…ç½®"""
    global is_loading_config
    is_loading_config = True
    
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                config = json.load(f)

            def cfg(key, default):
                val = config.get(key)
                if val is None or val == "":
                    return default
                return val

            endpoint_val = cfg("endpoint", "OpenAI")
            endpoint2_val = cfg("endpoint2", "OpenAI")
            choice_val = cfg("choice", False)
            
            result = (
                endpoint_val,
                cfg("model", "gpt-4o"),
                cfg("api_key", ""),
                gr.update(value=cfg("base", ""), visible=(endpoint_val == "CUSTOM")),
                endpoint2_val,
                cfg("model2", "gpt-4o"),
                cfg("api_key2", ""),
                gr.update(value=cfg("base2", ""), visible=(endpoint2_val == "CUSTOM")),
                cfg("source_lang", "Chinese"),
                cfg("target_lang", "English"),
                cfg("country", "United States"),
                cfg("max_tokens", 1000),
                cfg("temperature", 0.3),
                cfg("rpm", 60),
                choice_val,
                gr.update(value="âœ… å·²è‡ªåŠ¨åŠ è½½å†å²é…ç½®", visible=True),
                gr.update(visible=choice_val),
            )
            is_loading_config = False
            return result
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ—¶å‡ºé”™: {e}")
        is_loading_config = False
        pass
    
    is_loading_config = False
    return (
        "OpenAI", "gpt-4o", "", gr.update(value="", visible=False),
        "OpenAI", "gpt-4o", "", gr.update(value="", visible=False),
        "Chinese", "English", "United States",
        1000, 0.3, 60, False,
        gr.update(value="ä½¿ç”¨é»˜è®¤é…ç½®", visible=True),
        gr.update(visible=False),
    )


def update_model(endpoint, current_model=None):
    """æ›´æ–°æ¨¡å‹å"""
    global is_loading_config
    
    endpoint_model_map = {
        "Groq": "llama3-70b-8192",
        "OpenAI": "gpt-4o",
        "TogetherAI": "Qwen/Qwen2-72B-Instruct",
        "Ollama": "llama3",
        "CUSTOM": "",
    }
    
    default_model = endpoint_model_map.get(endpoint, "")
    
    if is_loading_config:
        model_update = gr.update()
    elif current_model and current_model.strip() and current_model != default_model:
        model_update = gr.update()
    else:
        model_update = gr.update(value=default_model)
    
    if endpoint == "CUSTOM":
        base = gr.update(visible=True, placeholder="ä¾‹å¦‚: http://localhost:11434")
    else:
        base = gr.update(visible=False)
    
    return model_update, base


def read_uploaded_files(files: List) -> List[Tuple[str, str]]:
    """è¯»å–ä¸Šä¼ çš„æ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶åå’Œå†…å®¹"""
    file_contents = []
    
    if not files:
        return file_contents
    
    for file in files:
        try:
            if isinstance(file, str):
                file_path = file
            else:
                file_path = file.name if hasattr(file, 'name') else str(file)
            
            if not file_path or not os.path.exists(file_path):
                continue
            
            # è·å–åŸå§‹æ–‡ä»¶å
            original_filename = os.path.basename(file_path)
            name_without_ext = os.path.splitext(original_filename)[0]
            
            # æå–æ–‡ä»¶æ‰©å±•å
            if "." not in os.path.basename(file_path):
                continue
            
            file_type = os.path.splitext(file_path)[1][1:].lower()
            
            if file_type in ["pdf", "txt", "py", "docx", "json", "cpp", "md"]:
                if file_type == "pdf":
                    content = extract_pdf(file_path)
                elif file_type == "docx":
                    content = extract_docx(file_path)
                else:
                    content = extract_text(file_path)
                
                # æ¸…ç†å†…å®¹
                content = re.sub(r"(?m)^\s*$\n?", "", content)
                if content.strip():
                    file_contents.append((name_without_ext, content))
                    
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            continue
    
    return file_contents


def translate_single_file(
    task: TranslationTask,
    endpoint: str, base: str, model: str, api_key: str,
    choice: bool, endpoint2: str, base2: str, model2: str, api_key2: str,
    source_lang: str, target_lang: str, country: str,
    max_tokens: int, temperature: int, rpm: int
) -> TranslationTask:
    """ç¿»è¯‘å•ä¸ªæ–‡ä»¶"""
    try:
        task.status = "ç¿»è¯‘ä¸­"
        task.start_time = time.time()
        task.progress = 10
        
        # åŠ è½½æ¨¡å‹
        model_load(endpoint, base, model, api_key, temperature, rpm)
        task.progress = 20
        
        # æ‰§è¡Œç¿»è¯‘
        if choice:
            init_translation, reflect_translation, final_translation = translator_sec(
                endpoint2=endpoint2,
                base2=base2,
                model2=model2,
                api_key2=api_key2,
                source_lang=source_lang,
                target_lang=target_lang,
                source_text=task.content,
                country=country,
                max_tokens=max_tokens,
            )
        else:
            init_translation, reflect_translation, final_translation = translator(
                source_lang=source_lang,
                target_lang=target_lang,
                source_text=task.content,
                country=country,
                max_tokens=max_tokens,
            )
        
        task.init_translation = init_translation
        task.reflect_translation = reflect_translation
        task.final_translation = final_translation
        task.progress = 100
        task.status = "å·²å®Œæˆ"
        task.end_time = time.time()
        
    except Exception as e:
        task.status = "å¤±è´¥"
        task.error_message = str(e)
        task.progress = 0
        task.end_time = time.time()
    
    return task


def start_batch_translation(
    files,
    output_folder: str,
    endpoint: str, base: str, model: str, api_key: str,
    choice: bool, endpoint2: str, base2: str, model2: str, api_key2: str,
    source_lang: str, target_lang: str, country: str,
    max_tokens: int, temperature: int, rpm: int
):
    """å¼€å§‹æ‰¹é‡ç¿»è¯‘"""
    global translation_tasks, task_counter
    
    if not files:
        return "âŒ è¯·å…ˆä¸Šä¼ æ–‡ä»¶", gr.update(), gr.update()
    
    if not output_folder or not os.path.exists(output_folder):
        # å°è¯•åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        try:
            os.makedirs(output_folder, exist_ok=True)
        except:
            return "âŒ è¯·é€‰æ‹©æœ‰æ•ˆçš„è¾“å‡ºæ–‡ä»¶å¤¹", gr.update(), gr.update()
    
    if not source_lang or not target_lang or source_lang == target_lang:
        return "âŒ è¯·æ£€æŸ¥æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€è®¾ç½®", gr.update(), gr.update()
    
    # è¯»å–æ–‡ä»¶å†…å®¹
    file_contents = read_uploaded_files(files)
    if not file_contents:
        return "âŒ æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„æ–‡ä»¶å†…å®¹", gr.update(), gr.update()
    
    # åˆ›å»ºç¿»è¯‘ä»»åŠ¡
    tasks = []
    for filename, content in file_contents:
        task_counter += 1
        task_id = f"task_{task_counter}"
        task = TranslationTask(task_id, filename, content)
        translation_tasks[task_id] = task
        tasks.append(task)
    
    # ä¿å­˜é…ç½®
    save_config(
        endpoint, model, api_key, base,
        endpoint2, model2, api_key2, base2,
        source_lang, target_lang, country,
        max_tokens, temperature, rpm, choice
    )
    
    # å¯åŠ¨åå°ç¿»è¯‘çº¿ç¨‹
    def run_translations():
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT_TASKS) as executor:
            future_to_task = {
                executor.submit(
                    translate_single_file,
                    task,
                    endpoint, base, model, api_key,
                    choice, endpoint2, base2, model2, api_key2,
                    source_lang, target_lang, country,
                    max_tokens, temperature, rpm
                ): task for task in tasks
            }
            
            for future in as_completed(future_to_task):
                task = future_to_task[future]
                try:
                    completed_task = future.result()
                    # ä¿å­˜ç¿»è¯‘ç»“æœåˆ°æ–‡ä»¶
                    if completed_task.status == "å·²å®Œæˆ":
                        save_translation_to_file(completed_task, output_folder)
                except Exception as e:
                    task.status = "å¤±è´¥"
                    task.error_message = str(e)
    
    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œç¿»è¯‘
    threading.Thread(target=run_translations, daemon=True).start()
    
    status_msg = f"âœ… å·²å¼€å§‹ç¿»è¯‘ {len(tasks)} ä¸ªæ–‡ä»¶ï¼Œæœ€å¤§å¹¶å‘æ•°: {MAX_CONCURRENT_TASKS}"
    return status_msg, update_progress_display(), gr.update(visible=True)


def clean_translation_for_novel(translation_text):
    """æ¸…ç†ç¿»è¯‘å†…å®¹ï¼Œä½¿å…¶é€‚åˆå°è¯´ç½‘ç«™é˜…è¯»
    
    ç§»é™¤AIç”Ÿæˆçš„æç¤ºæ€§æ–‡å­—ï¼Œä¼˜åŒ–æ ¼å¼
    """
    if not translation_text:
        return ""
    
    # éœ€è¦ç§»é™¤çš„æç¤ºæ€§çŸ­è¯­åˆ—è¡¨ï¼ˆä¸­è‹±æ–‡ï¼‰
    ai_markers = [
        "ç¿»è¯‘å¦‚ä¸‹ï¼š", "ç¿»è¯‘å¦‚ä¸‹:", "ç¿»è¯‘ï¼š", "ç¿»è¯‘:",
        "æ­£æ–‡å¦‚ä¸‹ï¼š", "æ­£æ–‡å¦‚ä¸‹:", "æ­£æ–‡ï¼š", "æ­£æ–‡:",
        "Translation:", "Translation as follows:", "TRANSLATION:", "TRANSLATION",
        "Here is the translation:", "Here's the translation:",
        "The translation is:", "Translated text:",
        "ä»¥ä¸‹æ˜¯ç¿»è¯‘ï¼š", "ä»¥ä¸‹æ˜¯ç¿»è¯‘:", "ä»¥ä¸‹ä¸ºç¿»è¯‘ï¼š", "ä»¥ä¸‹ä¸ºç¿»è¯‘:",
        "è¯‘æ–‡å¦‚ä¸‹ï¼š", "è¯‘æ–‡å¦‚ä¸‹:", "è¯‘æ–‡ï¼š", "è¯‘æ–‡:",
        "è‹±æ–‡ç¿»è¯‘ï¼š", "è‹±æ–‡ç¿»è¯‘:", "è‹±è¯‘ï¼š", "è‹±è¯‘:",
        "ä¸­æ–‡ç¿»è¯‘ï¼š", "ä¸­æ–‡ç¿»è¯‘:", "ä¸­è¯‘ï¼š", "ä¸­è¯‘:",
    ]
    
    lines = translation_text.strip().split('\n')
    cleaned_lines = []
    
    for i, line in enumerate(lines):
        line_stripped = line.strip()
        
        # è·³è¿‡ç©ºè¡Œï¼ˆä½†ä¿ç•™ç”¨äºæ®µè½åˆ†éš”ï¼‰
        if not line_stripped:
            cleaned_lines.append('')
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯AIæç¤ºæ€§æ–‡å­—ï¼ˆé€šå¸¸åœ¨å¼€å¤´å‡ è¡Œï¼‰
        if i < 3:  # åªæ£€æŸ¥å‰3è¡Œ
            is_marker = False
            for marker in ai_markers:
                if line_stripped.startswith(marker) or line_stripped == marker:
                    is_marker = True
                    print(f"[æ ¼å¼æ¸…ç†] ç§»é™¤AIæ ‡è®°: {line_stripped}")
                    break
            
            if is_marker:
                continue  # è·³è¿‡è¿™ä¸€è¡Œ
        
        # ä¿ç•™è¿™ä¸€è¡Œ
        cleaned_lines.append(line)
    
    # é‡æ–°ç»„åˆæ–‡æœ¬
    cleaned_text = '\n'.join(cleaned_lines)
    
    # ç§»é™¤å¼€å¤´çš„å¤šä½™ç©ºè¡Œ
    cleaned_text = cleaned_text.lstrip('\n')
    
    # ç¡®ä¿æ®µè½ä¹‹é—´æœ‰é€‚å½“çš„ç©ºè¡Œï¼ˆå°è¯´æ ¼å¼ï¼‰
    # å°†å¤šä¸ªè¿ç»­ç©ºè¡Œå‹ç¼©ä¸ºæœ€å¤š2ä¸ªç©ºè¡Œ
    import re
    cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)
    
    # ç§»é™¤è¡Œå°¾ç©ºæ ¼
    cleaned_text = '\n'.join(line.rstrip() for line in cleaned_text.split('\n'))
    
    print(f"[æ ¼å¼æ¸…ç†] å®Œæˆï¼ŒåŸå§‹é•¿åº¦: {len(translation_text)}, æ¸…ç†åé•¿åº¦: {len(cleaned_text)}")
    
    return cleaned_text


def save_translation_to_file(task: TranslationTask, output_folder: str):
    """ä¿å­˜ç¿»è¯‘ç»“æœåˆ°æ–‡ä»¶ - åªè¾“å‡ºæœ€ç»ˆç¿»è¯‘å†…å®¹"""
    try:
        output_filename = f"{task.filename}_translated.txt"
        output_path = os.path.join(output_folder, output_filename)
        
        # æ¸…ç†å’Œæ ¼å¼åŒ–ç¿»è¯‘å†…å®¹ï¼Œä½¿å…¶é€‚åˆå°è¯´ç½‘ç«™é˜…è¯»
        cleaned_content = clean_translation_for_novel(task.final_translation)
        
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(cleaned_content)
        
        print(f"ç¿»è¯‘ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        task.status = "ä¿å­˜å¤±è´¥"
        task.error_message = f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}"


def update_progress_display():
    """æ›´æ–°è¿›åº¦æ˜¾ç¤º"""
    if not translation_tasks:
        return gr.update(value="æš‚æ— ç¿»è¯‘ä»»åŠ¡", visible=False)
    
    progress_html = """
    <div style="font-family: monospace; background: #f5f5f5; padding: 15px; border-radius: 8px;">
        <h3 style="margin-top: 0; color: #333;">ğŸ“Š ç¿»è¯‘è¿›åº¦</h3>
    """
    
    completed_count = 0
    total_count = len(translation_tasks)
    
    for task_id, task in translation_tasks.items():
        status_color = {
            "ç­‰å¾…ä¸­": "#ffa500",
            "ç¿»è¯‘ä¸­": "#007bff", 
            "å·²å®Œæˆ": "#28a745",
            "å¤±è´¥": "#dc3545",
            "ä¿å­˜å¤±è´¥": "#dc3545"
        }.get(task.status, "#6c757d")
        
        if task.status == "å·²å®Œæˆ":
            completed_count += 1
        
        # è®¡ç®—è€—æ—¶
        elapsed_time = ""
        if task.start_time:
            if task.end_time:
                elapsed = task.end_time - task.start_time
                elapsed_time = f" ({elapsed:.1f}s)"
            else:
                elapsed = time.time() - task.start_time
                elapsed_time = f" ({elapsed:.1f}s)"
        
        progress_html += f"""
        <div style="margin: 8px 0; padding: 8px; background: white; border-radius: 4px; border-left: 4px solid {status_color};">
            <div style="display: flex; justify-content: space-between; align-items: center;">
                <span style="font-weight: bold;">{task.filename}</span>
                <span style="color: {status_color}; font-weight: bold;">{task.status}{elapsed_time}</span>
            </div>
            <div style="margin-top: 4px;">
                <div style="background: #e9ecef; height: 6px; border-radius: 3px; overflow: hidden;">
                    <div style="background: {status_color}; height: 100%; width: {task.progress}%; transition: width 0.3s;"></div>
                </div>
                <small style="color: #666;">è¿›åº¦: {task.progress}%</small>
            </div>
            {f'<div style="color: #dc3545; font-size: 12px; margin-top: 4px;">é”™è¯¯: {task.error_message}</div>' if task.error_message else ''}
        </div>
        """
    
    progress_html += f"""
        <div style="margin-top: 15px; padding: 10px; background: #e3f2fd; border-radius: 4px;">
            <strong>æ€»ä½“è¿›åº¦: {completed_count}/{total_count} å·²å®Œæˆ</strong>
        </div>
    </div>
    """
    
    return gr.update(value=progress_html, visible=True)


def clear_all_tasks():
    """æ¸…ç©ºæ‰€æœ‰ä»»åŠ¡"""
    global translation_tasks
    translation_tasks.clear()
    return "âœ… å·²æ¸…ç©ºæ‰€æœ‰ä»»åŠ¡", gr.update(visible=False)


def enable_sec(choice):
    if choice:
        return gr.update(visible=True)
    else:
        return gr.update(visible=False)


def update_menu(visible):
    return not visible, gr.update(visible=not visible)


TITLE = """
    <div style="display: inline-flex;">
        <div style="margin-left: 6px; font-size:32px; color: #6366f1"><b>ç¿»è¯‘åŠ©æ‰‹</b> æœ¬åœ°æ‰¹é‡ç‰ˆ</div>
    </div>
"""

CSS = """
    h1 {
        text-align: center;
        display: block;
        height: 10vh;
        align-content: center;
    }
    footer {
        visibility: hidden;
    }
    .menu_btn {
        width: 48px;
        height: 48px;
        max-width: 48px;
        min-width: 48px;
        padding: 0px;
        background-color: transparent;
        border: none;
        cursor: pointer;
        position: relative;
        box-shadow: none;
    }
    .menu_btn::before,
    .menu_btn::after {
        content: '';
        position: absolute;
        width: 30px;
        height: 3px;
        background-color: #4f46e5;
        transition: transform 0.3s ease;
    }
    .menu_btn::before {
        top: 12px;
        box-shadow: 0 8px 0 #6366f1;
    }
    .menu_btn::after {
        bottom: 16px;
    }
    .menu_btn.active::before {
        transform: translateY(8px) rotate(45deg);
        box-shadow: none;
    }
    .menu_btn.active::after {
        transform: translateY(-8px) rotate(-45deg);
    }
    .lang {
        max-width: 100px;
        min-width: 100px;
    }
    .progress-container {
        max-height: 400px;
        overflow-y: auto;
        border: 1px solid #ddd;
        border-radius: 8px;
        padding: 10px;
        background: #f9f9f9;
    }
"""

JS = """
    function () {
        const menu_btn = document.getElementById('menu');
        menu_btn.classList.toggle('active');
    }
"""

with gr.Blocks(theme="soft", css=CSS, fill_height=True) as demo:
    with gr.Row():
        visible = gr.State(value=True)
        menu_btn = gr.Button(
            value="", elem_classes="menu_btn", elem_id="menu", size="sm"
        )
        gr.HTML(TITLE)
    
    with gr.Row():
        with gr.Column(scale=1) as menubar:
            endpoint = gr.Dropdown(
                label="APIç«¯ç‚¹",
                choices=["OpenAI", "Groq", "TogetherAI", "Ollama", "CUSTOM"],
                value="OpenAI",
            )
            choice = gr.Checkbox(
                label="é¢å¤–ç«¯ç‚¹",
                info="ç”¨äºåæ€æ­¥éª¤çš„é¢å¤–ç«¯ç‚¹",
            )
            model = gr.Textbox(
                label="æ¨¡å‹",
                value="gpt-4o",
            )
            api_key = gr.Textbox(
                label="APIå¯†é’¥",
                type="password",
            )
            base = gr.Textbox(
                label="åŸºç¡€URL", 
                visible=False,
                placeholder="ä¾‹å¦‚: http://localhost:11434"
            )
            
            with gr.Column(visible=False) as AddEndpoint:
                endpoint2 = gr.Dropdown(
                    label="é¢å¤–ç«¯ç‚¹",
                    choices=["OpenAI", "Groq", "TogetherAI", "Ollama", "CUSTOM"],
                    value="OpenAI",
                )
                model2 = gr.Textbox(
                    label="æ¨¡å‹",
                    value="gpt-4o",
                )
                api_key2 = gr.Textbox(
                    label="APIå¯†é’¥",
                    type="password",
                )
                base2 = gr.Textbox(
                    label="åŸºç¡€URL", 
                    visible=False,
                    placeholder="ä¾‹å¦‚: http://localhost:11434"
                )
            
            with gr.Row():
                source_lang = gr.Textbox(
                    label="æºè¯­è¨€",
                    value="Chinese",
                    elem_classes="lang",
                )
                target_lang = gr.Textbox(
                    label="ç›®æ ‡è¯­è¨€",
                    value="English",
                    elem_classes="lang",
                )
            
            country = gr.Textbox(
                label="åœ°åŒº", value="United States", max_lines=1
            )
            
            with gr.Accordion("é«˜çº§é€‰é¡¹", open=False):
                max_tokens = gr.Slider(
                    label="æ¯å—æœ€å¤§Tokenæ•°",
                    minimum=512,
                    maximum=2046,
                    value=1000,
                    step=8,
                )
                temperature = gr.Slider(
                    label="æ¸©åº¦",
                    minimum=0,
                    maximum=1.0,
                    value=0.3,
                    step=0.1,
                )
                rpm = gr.Slider(
                    label="æ¯åˆ†é’Ÿè¯·æ±‚æ•°",
                    minimum=1,
                    maximum=1000,
                    value=60,
                    step=1,
                )
            
            save_config_btn = gr.Button(value="ğŸ’¾ ä¿å­˜é…ç½®", variant="secondary", size="sm")
            config_status = gr.Textbox(
                label="é…ç½®çŠ¶æ€", 
                visible=True, 
                interactive=False,
                value="é…ç½®å°†è‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶",
                lines=1
            )

        with gr.Column(scale=4):
            gr.Markdown("### ğŸ“ æ‰¹é‡ç¿»è¯‘")
            
            with gr.Row():
                files_upload = gr.File(
                    label="ğŸ“¤ ä¸Šä¼ å¤šä¸ªæ–‡ä»¶",
                    file_count="multiple",
                    file_types=["text", ".pdf", ".docx", ".txt", ".md", ".py", ".json", ".cpp"]
                )
                output_folder = gr.Textbox(
                    label="ğŸ“‚ è¾“å‡ºæ–‡ä»¶å¤¹",
                    placeholder="é€‰æ‹©ä¿å­˜ç¿»è¯‘ç»“æœçš„æ–‡ä»¶å¤¹è·¯å¾„",
                    value=os.path.expanduser("~/Desktop/translations")
                )
            
            with gr.Row():
                start_btn = gr.Button(value="ğŸš€ å¼€å§‹æ‰¹é‡ç¿»è¯‘", variant="primary", size="lg")
                clear_btn = gr.Button(value="ğŸ—‘ï¸ æ¸…ç©ºä»»åŠ¡", variant="secondary")
            
            status_display = gr.Textbox(
                label="çŠ¶æ€",
                value="è¯·ä¸Šä¼ æ–‡ä»¶å¹¶é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹",
                interactive=False,
                lines=2
            )
            
            progress_display = gr.HTML(
                value="",
                visible=False,
                elem_classes="progress-container"
            )
    
    # é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨åŠ è½½é…ç½®
    demo.load(
        fn=load_config,
        outputs=[
            endpoint, model, api_key, base,
            endpoint2, model2, api_key2, base2,
            source_lang, target_lang, country,
            max_tokens, temperature, rpm, choice,
            config_status, AddEndpoint
        ]
    )
    
    menu_btn.click(
        fn=update_menu, inputs=visible, outputs=[visible, menubar], js=JS
    )
    
    endpoint.change(fn=update_model, inputs=[endpoint, model], outputs=[model, base])
    choice.select(fn=enable_sec, inputs=[choice], outputs=[AddEndpoint])
    endpoint2.change(fn=update_model, inputs=[endpoint2, model2], outputs=[model2, base2])
    
    save_config_btn.click(
        fn=save_config,
        inputs=[
            endpoint, model, api_key, base,
            endpoint2, model2, api_key2, base2,
            source_lang, target_lang, country,
            max_tokens, temperature, rpm, choice
        ],
        outputs=[config_status]
    )
    
    start_btn.click(
        fn=start_batch_translation,
        inputs=[
            files_upload, output_folder,
            endpoint, base, model, api_key,
            choice, endpoint2, base2, model2, api_key2,
            source_lang, target_lang, country,
            max_tokens, temperature, rpm
        ],
        outputs=[status_display, progress_display, progress_display]
    )
    
    clear_btn.click(
        fn=clear_all_tasks,
        outputs=[status_display, progress_display]
    )
    
    # å®šæ—¶æ›´æ–°è¿›åº¦æ˜¾ç¤º
    demo.load(
        fn=lambda: None,
        every=2,  # æ¯2ç§’æ›´æ–°ä¸€æ¬¡
    ).then(
        fn=update_progress_display,
        outputs=[progress_display]
    )


if __name__ == "__main__":
    import os
    import sys
    
    # ç¦ç”¨ API ä¿¡æ¯ç”Ÿæˆ
    os.environ["GRADIO_ANALYTICS_ENABLED"] = "False"
    
    # åˆ›å»ºé»˜è®¤è¾“å‡ºæ–‡ä»¶å¤¹
    default_output = os.path.expanduser("~/Desktop/translations")
    os.makedirs(default_output, exist_ok=True)
    
    try:
        demo.queue(api_open=False).launch(
            server_name="127.0.0.1", 
            server_port=7861, 
            share=False, 
            inbrowser=True
        )
    except KeyboardInterrupt:
        print("Shutting down...")
        sys.exit(0)
    except Exception as e:
        print(f"Error during launch: {e}")
        print("Trying alternative launch method...")
        try:
            demo.launch(
                server_name="127.0.0.1", 
                server_port=7861, 
                share=False, 
                inbrowser=True
            )
        except Exception as e2:
            print(f"Alternative launch also failed: {e2}")
            sys.exit(1)